library(data.table)
dat = lapply(list.files(path = "healthcare2", pattern = "*.csv"),
fread)
library(data.table)
dat = lapply(list.files(path = "healthcare2/", pattern = "*.csv"),
fread)
library(data.table)
data_path = "healthcare2/"
csv_files = list.files(path = data_path, pattern = "*.csv")
readallcsv = function(i){
assign(
gsub(".csv", "", csv_files[i]),
fread(paste0(data_path, csv_files[i])),
envir = parent.frame()
)
}
for (i in seq_along(csv_files))  readallcsv(i)
head(Patients)
head(Patient)
Patient[!Gender %in% c("female", "male"), Gender := "other"]
q3 = Mortality[Patient, on = "PatientID"]
View(q3)
table(substr(q3$DateOfDeath, 1, 4))
table(substr(q3$DateOfBirth, 1, 4))
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
install.packages("reticulate")
f
use_python("~\\Anaconda3\\python.exe")
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
data_path = "healthcare2/"
csv_files = list.files(path = data_path, pattern = "*.csv")
readallcsv = function(i){
assign(
gsub(".csv", "", csv_files[i]),
fread(paste0(data_path, csv_files[i])),
envir = parent.frame()
)
}
for (i in seq_along(csv_files))  readallcsv(i)
Patient[!Gender %in% c("female", "male"), Gender := "other"]
q1 = Mortality[Patient, on = "PatientID"]
q1[, .(death_percent = sum(!is.na(DateOfDeath))/.N), by = Gender][order(-death_percent)]
library(data.table)
data_path = "healthcare2/"
csv_files = list.files(path = data_path, pattern = "*.csv")
readallcsv = function(i){
assign(
gsub(".csv", "", csv_files[i]),
fread(paste0(data_path, csv_files[i])),
envir = parent.frame()
)
}
for (i in seq_along(csv_files))  readallcsv(i)
OutpatientVisit = melt(
OutpatientVisit,
measure.vars = patterns("^ICD10"),
id.vars = c("VisitID", "PatientID"),
value.name = "ICD10"
)
num_gender = Patient[, .N, by = Gender]
DiseaseMap[
OutpatientVisit, on = "ICD10"
]
q2 = DiseaseMap[
OutpatientVisit, on = "ICD10"
][, .N, by = .(PatientID, Condition)][Patient, on = "PatientID"]
View(q2)
q2_1 = q2[,.(condition_N = .N), by = .(Condition, Gender)]
q2_1
?CJ
CJ(c(5,NA,1), c(1,3,2))
install.packages("Hmisc")
?substr
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
## import needed data
## patient data with gender
patients <-
fread('healthcare2/Patient.csv')
## mortality table
mortality <-
fread('healthcare2/Mortality.csv')
library(Hmisc)
describe(patients[,list(PatientID,Gender)])
analytic_patients <-
patients[,list(PatientID,
Gender_clean = factor(Gender,levels=c('male','female')))]
describe(analytic_patients)
# Check to make sure the mortality file is unique by patientID (or the merge will have issues)
describe(mortality) ## looks good
## merge Date of death to the analytic file
setkey(analytic_patients, PatientID)
setkey(mortality,PatientID)
analytic_patients[mortality,
DateOfDeath := i.DateOfDeath]
## assume missing date of deaths are alive
analytic_patients[is.na(DateOfDeath), Dead := 'No']
analytic_patients[!is.na(DateOfDeath), Dead := 'Yes']
## overall mortality rate
analytic_patients[,list(mortality_rate= sum(Dead == 'Yes')/.N)]
## rate by gender
analytic_patients[,list(mortality_rate= sum(Dead == 'Yes')/.N),
by=Gender_clean]
analytic_patients[,chisq.test(table(Dead,Gender_clean))] # not significant
## using logistic regression
analytic_patients[,summary(glm(Dead=='Yes' ~ Gender_clean, family = binomial))] # not significant
## Include the missing data as a valid level
analytic_patients[is.na(Gender_clean),Gender_clean:='Missing']
## using logistic regression
analytic_patients[,summary(glm(Dead=='Yes' ~ Gender_clean, family = binomial))] # still not significant
## visits
outpat <-
fread('healthcare2/OutpatientVisit.csv')
## check it out
head(outpat)
describe(outpat)
## none?
outpat[is.na(VisitDate)]
## they are blanks
outpat[,head(sort(unique(VisitDate)))]
outpat[,tail(sort(unique(VisitDate)))]
outpat[VisitDate == '']
## identify patients at risk
## at least one outpatient visit, remove the missing visit dates
pts_risk <-
outpat[VisitDate != '',list(PatientID=unique(PatientID))]
## add their gender
setkey(pts_risk,PatientID)
setkey(analytic_patients,PatientID)
pts_risk[analytic_patients,Gender_clean:=i.Gender_clean]
## summarize the risk set
pts_risk[,.N]
pts_risk[,.N,by=Gender_clean]
## disease_map
disease_map <-
fread('healthcare2/DiseaseMap.csv')
## check the number of conditions
disease_map[,uniqueN(Condition)]
setkey(outpat,PatientID)
setkey(pts_risk,PatientID)
diag_long <-
melt(outpat[pts_risk],
na.rm = T,
id.vars = 'PatientID',
measure.vars = c('ICD10_1', 'ICD10_2', 'ICD10_3'))[value !='',list(PatientID,value)] # remove the blanks after the melt
## check it out
diag_long
## Merge the disease map file
setkey(diag_long,value)
setkey(disease_map,ICD10)
diag_long_patient <-
disease_map[diag_long][,.N,by=list(PatientID,Condition)]
diag_long_patient
## example cartesian product for clarity
## CJ is the data.table way, returns a data.table
CJ(c(1,2,3),
c('a','b','c'))
## expand.grid is the base R way, returns a dataframe
expand.grid(c(1,2,3),c('a','b','c'))
## now do this with patients and conditions using CJ
patient_condition <-
CJ(PatientID=pts_risk[,unique(PatientID)],
Condition=disease_map[,unique(Condition)])
## merge in the disease count
setkey(patient_condition,PatientID,Condition)
setkey(diag_long_patient,PatientID,Condition)
patient_condition[diag_long_patient,N:=N]
patient_condition[is.na(N),N:=0]
## merge in gender
setkey(patient_condition,PatientID)
setkey(pts_risk,PatientID)
patient_condition[pts_risk,Gender_clean:=Gender_clean]
## convert N to yes/no (0/1)
patient_condition[,condition_01:=ifelse(N==0,0,1)]
## mean condition for everyone (excluding missing gender - you could also keep them and add another column)
setkey(patient_condition,Gender_clean)
patient_condition[J(c('female','male')),
list(Overall = mean(condition_01)),
by=Condition]
## save and format
library(scales)
percent(0.34) ## test
condition_all <-
patient_condition[J(c('female','male')),
list(Overall = percent(mean(condition_01))),
by=Condition]
## calculate by gender
condition_gender <-
patient_condition[J(c('female','male')),
list(Overall = percent(mean(condition_01))),
by=list(Condition,Gender_clean)]
## cast to wide
condition_gender_wide <-
dcast(condition_gender,Condition ~ Gender_clean)
## Combine with the overall column
setkey(condition_gender_wide,Condition)
setkey(condition_all,Condition)
condition_all[condition_gender_wide]
## the minimum visit date is blank!
outpat[,list(min(VisitDate),max(VisitDate))]
## let's exclude the blanks
outpat[VisitDate != '',
list(min(VisitDate),max(VisitDate))]
## 2005 to 2018
## identify unique patients / years combination
patient_years <-
CJ(PatientID=outpat[VisitDate!='',unique(PatientID)],
Years=2005:2018)
## identify first outpat date
pat_min_vis <-
outpat[VisitDate!='',list(min_vis = min(VisitDate)),by=PatientID]
## add to file
setkey(patient_years,PatientID)
setkey(pat_min_vis,PatientID)
patient_years[pat_min_vis,
min_vis:=as.numeric(substr(min_vis,start = 1,stop = 4))]
## add mortality
setkey(mortality,PatientID)
patient_years[mortality,
death_yr:=as.numeric(substr(DateOfDeath,start = 1,stop = 4))]
## compare years to see if patient died in a given year
patient_years[Years >= death_yr, dead := 1]
patient_years[is.na(dead), dead :=0]
## spot check the data
patient_years[PatientID == 1]
patient_years[PatientID == 2]
## looks good
## implement logic for at-risk
patient_years[Years < min_vis,
at_risk := 'no']
patient_years[Years >= min_vis,
at_risk := 'yes']
patient_years[Years > death_yr,
at_risk := 'no']
## spot check again
patient_years[PatientID == 1]
patient_years[PatientID == 2]
## looks good!
dim
dim(patient_years)
View(patient_years)
patient_years[at_risk == 'yes',
list(n_unique_patients = uniqueN(PatientID),
n_at_risk = .N,
n_dead = sum(dead),
mortality_rate=mean(dead)),
by=Years]
patient_years[at_risk == 'yes']
dim(patient_years[at_risk == 'yes'])
patient_years[at_risk == 'yes',
list(n_unique_patients = uniqueN(PatientID),
n_at_risk = .N,
n_dead = sum(dead),
mortality_rate=mean(dead)),
keyby=Years]  ## keyby sorts it by years
library(gapminder)
data(gapminder)
rm(list = ls())
library(gapminder)
data(gapminder)
gapminder
pacman::p_load(gapminder, data.table)
data(gapminder)
gapminder = data.table(gapminder)
View(gapminder)
names(gapminder)
gapminder[year == 2007, median_lifeExp = median(lifeExp), continent]
gapminder[year == 2007, .(median_lifeExp = median(lifeExp)), continent]
gapminder[year == 2007, .(median_lifeExp = median(lifeExp)), keyby = continent]
pacman::p_load(gapminder, data.table, parallel, doParallel)
detectCores()
gapminder[year == 2007, .(median_lifeExp = median(lifeExp,na.rm=T)), keyby = continent]
gapminder2007 = gapminder[year == 2007]
gapminder2007[, .(median_lifeExp = median(lifeExp,na.rm=T)), keyby = continent]
detectCores()
cl <- makeCluster(3)
registerDoParallel(cl)
n_boot = 1e4
gc()
# Not parallel
starttime1 = Sys.time()
result1 <-
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
median(lifeExp, na.rm=T), keyby = continent]
temp_result
}
endtime1 <- Sys.time()
endtime1 - starttime1
hist(result1)
result1[1]
result1[[1]]
result1[2]
result1[3]
result1[4]
detectCores()
cl <- makeCluster(3)
registerDoParallel(cl)
n_boot = 1e4
gc()
# Not parallel
starttime1 = Sys.time()
result1 <-
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
temp_result
}
endtime1 <- Sys.time()
endtime1 - starttime1
#hist(result1)
# Parallel version
rm(temp_result)
gc()
starttime2 <- Sys.time()
result2 <-
foreach(i=1:n_boot,
.combine='c',.packages = 'data.table') %dopar% {
temp_result = flights_sample[sample(.N,replace = T),
median(arr_delay,na.rm=T)]
temp_result
}
endtime2 <- Sys.time()
endtime2 - starttime2
#hist(result2)
rm(temp_result)
gc()
starttime2 <- Sys.time()
result2 <-
foreach(i=1:n_boot,
.combine='c',.packages = 'data.table') %dopar% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
temp_result
}
endtime2 <- Sys.time()
endtime2 - starttime2
result2[1]
result2[2]
mtcars = data.table(mtcars)
mtcars[,z:=1]
View(mtcars)
n_boot = 10
result1 = list()
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
temp_result[,index := 1]
}
result1 = list()
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
result1[[i]] = temp_result[,index := 1]
}
View(result1)
result1 = list()
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
result1[[i]] <- temp_result[,index := 1]
}
result1 = list()
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
re
result1 = list()
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
result1[i] <- temp_result[,index := 1]
}
result1 = list()
foreach(i=1:n_boot, .combine='c') %do% {
temp_result = gapminder2007[sample(.N, replace = T),
.(median_lifeExp = median(lifeExp, na.rm=T)),
keyby = continent]
result1[[i]] <- temp_result[,index := 1]
}
pacman::p_load(gapminder, data.table, parallel, doParallel, foreach, ggplot2)
data(gapminder)
gapminder = data.table(gapminder)
gapminder2007 = gapminder[year == 2007 & continent != 'Oceania']
View(gapminder2007)
detectCores()
library(brms)
load("F:/Onedrive/OneDrive - Saint Louis University/Orders/BayesianquantileTobit/fit/fit2.Rdata")
str(fit2)
brms::prior_summary(fit2)
brms::prior_summary(fit2, all = FALSE)
prior_summary(fit, all = FALSE), show_df = FALSE
print(prior_summary(fit, all = FALSE), show_df = FALSE)
print(prior_summary(fit2, all = FALSE), show_df = FALSE)
print(prior_summary(fit2, all = FALSE), show_df = TRUE)
plot(fit2)
get_variables(fit2)
require(tidybayes)
install.packages('tidybayes')
library(tidybayes)
get_variables(fit2)
prior_summary(fit2)
prior_samples(fit2, pars = 'b_Intercept')
prior_samples(fit2)
fit2
str(fit2)
fit2$prior
stancode(fit2)
?rt
stan_t = function(x, nu, mu, sigma){
factorial((nu+1)/2 - 1)/(factorial(nu/2 - 1))*(1/(sqrt(nu*pi)*sigma))*(1+1/nu*((x-nu)/sigma)^2)^(-(nu+1)/2)
}
prior_summary(fit2)
prior_summary(fit2, all= FALSE)
x = seq(-10, 10, 0.01)
simy = stan_t(x, 3, 1, 10)
plot(density(simy))
hist(simy)
plot(x, simy, type = 'l')
x = seq(-10, 100, 0.01)
simy = stan_t(x, 3, 1, 10)
plot(x, simy, type = 'l')
x = seq(-100, 100, 0.01)
simy = stan_t(x, 3, 1, 10)
plot(x, simy, type = 'l')
plot_t = function(nu, mu, sigma){
x = seq(-100, 100, 0.01)
simy = stan_t(x, nu, mu, sigma)
plot(x, simy, type = 'l', main = paste('t distribution with nu = ', nu, 'mu =', mu, 'sigma =', sigma))
}
plot_t = function(nu, mu, sigma){
x = seq(-100, 100, 0.01)
simy = stan_t(x, nu, mu, sigma)
plot(x, simy, type = 'l', main = paste('t distribution with nu = ', nu, 'mu =', mu, 'sigma =', sigma))
}
plot_t(3, 1, 10)
prior_summary(fit2)
plot_t(3, 0, 10)
zdsg
plot_t(3, 1, 10)
plot_t(3, 0, 10)
prior_summary(fit2, all = FALSE)
fit2
parnames(fit2)
vignette("brms_families")
prior_summary(fit2, all = FALSE)
str(fit2)
load("F:/Onedrive/OneDrive - Saint Louis University/Orders/BayesianquantileTobit/fit/fit01.Rdata")
f0 = qfit0
summary(f0)
stancode(f0)
prior_summary(f0)
