{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default figure size to be larger \n",
    "## this may only work in matplotlib 2.0+!\n",
    "matplotlib.rcParams['figure.figsize'] = [10.0,6.0]\n",
    "## Enable multiple outputs from jupyter cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wdbc.data',header=None,names = ['id_number', 'diagnosis', 'radius_mean', \n",
    "         'texture_mean', 'perimeter_mean', 'area_mean', \n",
    "         'smoothness_mean', 'compactness_mean', \n",
    "         'concavity_mean','concave_points_mean', \n",
    "         'symmetry_mean', 'fractal_dimension_mean',\n",
    "         'radius_se', 'texture_se', 'perimeter_se', \n",
    "         'area_se', 'smoothness_se', 'compactness_se', \n",
    "         'concavity_se', 'concave_points_se', \n",
    "         'symmetry_se', 'fractal_dimension_se', \n",
    "         'radius_worst', 'texture_worst', \n",
    "         'perimeter_worst', 'area_worst', \n",
    "         'smoothness_worst', 'compactness_worst', \n",
    "         'concavity_worst', 'concave_points_worst', \n",
    "         'symmetry_worst', 'fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_number diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnosis'].replace(\"M\", 0, inplace=True)\n",
    "data['diagnosis'].replace(\"B\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_number  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302          0        17.99         10.38          122.80     1001.0   \n",
       "1     842517          0        20.57         17.77          132.90     1326.0   \n",
       "2   84300903          0        19.69         21.25          130.00     1203.0   \n",
       "3   84348301          0        11.42         20.38           77.58      386.1   \n",
       "4   84358402          0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diagnosis ~ radius_mean + texture_mean + perimeter_mean + area_mean + smoothness_mean + compactness_mean + concavity_mean + concave_points_mean + symmetry_mean + fractal_dimension_mean'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = ['radius_mean','texture_mean','perimeter_mean',\n",
    "               'area_mean','smoothness_mean','compactness_mean','concavity_mean','concave_points_mean','symmetry_mean','fractal_dimension_mean']\n",
    "formula = \"diagnosis ~ \"  + \" + \".join(vars)\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use Patsy to create model matrices\n",
    "Y,X = dmatrices(formula,\n",
    "                data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (569, 1)\n",
       "  diagnosis\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          1\n",
       "          1\n",
       "          1\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "          0\n",
       "  [539 rows omitted]\n",
       "  Terms:\n",
       "    'diagnosis' (column 0)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (569, 11)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'radius_mean',\n",
       "     'texture_mean',\n",
       "     'perimeter_mean',\n",
       "     'area_mean',\n",
       "     'smoothness_mean',\n",
       "     'compactness_mean',\n",
       "     'concavity_mean',\n",
       "     'concave_points_mean',\n",
       "     'symmetry_mean',\n",
       "     'fractal_dimension_mean']\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'radius_mean' (column 1)\n",
       "    'texture_mean' (column 2)\n",
       "    'perimeter_mean' (column 3)\n",
       "    'area_mean' (column 4)\n",
       "    'smoothness_mean' (column 5)\n",
       "    'compactness_mean' (column 6)\n",
       "    'concavity_mean' (column 7)\n",
       "    'concave_points_mean' (column 8)\n",
       "    'symmetry_mean' (column 9)\n",
       "    'fractal_dimension_mean' (column 10)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish 20% test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Data into 80% training and 20% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X,\n",
    "                     np.ravel(Y), # prevents dimensionality error later! change dimention\n",
    "                     test_size=0.2,\n",
    "                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "#114 observations in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import linear model\n",
    "from sklearn import linear_model\n",
    "## Define model parameters\n",
    "## can implement penalties, but check docs for appropriate solver\n",
    "clf = linear_model.LogisticRegression(fit_intercept=True, # already have the intercept\n",
    "                                      solver='liblinear') # could change to lbfgs!\n",
    "## fit model using data with .fit\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70576824,  4.06963388, -0.17472315, -0.43201519, -0.02369288,\n",
       "        -0.41293936, -1.04197055, -1.43770159, -0.76568274, -0.60092706,\n",
       "        -0.08808622]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_\n",
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.90769231)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get mean accuracy\n",
    "clf.score(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,  30],\n",
       "       [ 12, 278]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train,\n",
    "                 clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955056179775281"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get kappa\n",
    "sklearn.metrics.cohen_kappa_score(y_train,\n",
    "                                  clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dict to store all these results:\n",
    "result_scores = {}\n",
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Function to Print Results\n",
    "def get_results(x1):\n",
    "    print(\"\\n{0:20}   {1:4}    {2:4}\".format('Model','Train','Test'))\n",
    "    print('-------------------------------------------')\n",
    "    for i in x1.keys():\n",
    "        print(\"{0:20}   {1:<6.4}   {2:<6.4}\".format(i,x1[i][0],x1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n"
     ]
    }
   ],
   "source": [
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(0.63736264)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy='most_frequent',\n",
    "                      random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Null'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n"
     ]
    }
   ],
   "source": [
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[137,  28],\n",
       "       [ 11, 279]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression with l1 penalty\n",
    "## Specify penalty directly as C = 1\n",
    "clf = linear_model.LogisticRegression(penalty='l1',\n",
    "                                      C=1, solver = 'liblinear') # specify penalty\n",
    "clf.fit(X_train,y_train)\n",
    "## get confusion matrix\n",
    "confusion_matrix(y_train,clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L1_C_1'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[135,  30],\n",
       "       [ 12, 278]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression with l1 penalty\n",
    "## Specify penalty directly as C = 1\n",
    "clf = linear_model.LogisticRegression(penalty='l2',\n",
    "                                      C=1, solver = 'liblinear') # specify penalty\n",
    "clf.fit(X_train,y_train)\n",
    "## get confusion matrix\n",
    "confusion_matrix(y_train,clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.90769231)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(0.92105263)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train) \n",
    "clf.score(X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L2_C_1'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net penalty logistic regression,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=32, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf= sklearn.linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=32)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n"
     ]
    }
   ],
   "source": [
    "result_scores['ElasticNet'] = \\\n",
    "            (clf.score(X_train,y_train),\n",
    "             clf.score(X_test,y_test) )\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[165,   0],\n",
       "       [  0, 290]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100, \n",
    "                                      max_features=10,\n",
    "                                      random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "## get confusion matrix\n",
    "confusion_matrix(y_train,clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['RandomForest_noCV'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient tree boosting: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "clf= sklearn.ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['GradientTree'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperprameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression withour regularization, no hyperparameter.<br>\n",
    "For LASSO, and Ridge, hyperparameters are alpha, which can affect the regularization effects. <br>\n",
    "For Elastic net penelty regression, there are hyperparameter α accounts for the relative importance of the LASSO and Ridge regularizations. There is another hyperparameter λ, that accounts for the amount of regularization used in the model.<br>\n",
    "For random forest, the hyperparameters are number of trees, and the max number of variables to consider for each tree, depth of the trees.<br>\n",
    "For grandient tree boosting, hyperparameters are learning rate, the number of boosting stages to perform, subsample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation for LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/lixue/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=20, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l1',\n",
       "           random_state=None, refit=True, scoring=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select the alpha through cross validation (k-folds leave one out)\n",
    "# auto generate 20 values between 1e-4 and 1e4 on log scale\n",
    "clf = linear_model.LogisticRegressionCV(cv=5,\n",
    "                                        Cs=20, ## takes awhile to fit 20 models!\n",
    "                                        penalty='l1',  #lasso\n",
    "                                        solver='liblinear') \n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n",
      "Logistic_L1_C_auto     0.9516   0.9474\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L1_C_auto'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([545.55947812])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 20 C's were fit\n",
    "clf.Cs\n",
    "## The values of C's \n",
    "clf.Cs_\n",
    "## The best fit C \n",
    "clf.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold validation for Rigde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=20, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select the alpha through cross validation (k-folds leave one out)\n",
    "# auto generate 20 values between 1e-4 and 1e4 on log scale\n",
    "clf = linear_model.LogisticRegressionCV(cv=5,\n",
    "                                        Cs=20, ## takes awhile to fit 20 models!\n",
    "                                        penalty='l2',  #ridge\n",
    "                                        solver='liblinear') \n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n",
      "Logistic_L1_C_auto     0.9516   0.9474\n",
      "Logistic_L2_C_auto     0.9473   0.9386\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L2_C_auto'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([10000.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 20 C's were fit\n",
    "clf.Cs\n",
    "## The values of C's \n",
    "clf.Cs_\n",
    "## The best fit C \n",
    "clf.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold validation for elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000,\n",
       "       n_alphas=100, n_jobs=None, normalize=False, positive=False,\n",
       "       precompute='auto', random_state=32, selection='cyclic', tol=0.0001,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5, eps=0.001, n_alphas=100, alphas=None, \n",
    "                                fit_intercept=True, precompute='auto', max_iter=1000, tol=0.0001,  verbose=0, positive=False, random_state=32)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12031987924163748"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.alpha_\n",
    "clf.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5951907017239848"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6098683896120006"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train) \n",
    "clf.score(X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n",
      "Logistic_L1_C_auto     0.9516   0.9474\n",
      "Logistic_L2_C_auto     0.9473   0.9386\n",
      "ElasticNetCV           0.5952   0.6099\n"
     ]
    }
   ],
   "source": [
    "result_scores['ElasticNetCV'] = \\\n",
    "            (clf.score(X_train,y_train),\n",
    "             clf.score(X_test,y_test) )\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, random forest CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=32, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': (50, 100, 200, 300), 'max_features': (2, 4, 6, 8, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "## specify grid\n",
    "parameters = {'n_estimators':(50,100,200,300),\n",
    "              'max_features':(2,4,6,8,10)}\n",
    "## specify model without hyperparameters\n",
    "rf_model = ensemble.RandomForestClassifier(random_state=32)\n",
    "## specify search with model\n",
    "clf = GridSearchCV(rf_model,\n",
    "                   parameters,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 4, 'n_estimators': 50}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## explore best hyperparameters\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n",
      "Logistic_L1_C_auto     0.9516   0.9474\n",
      "Logistic_L2_C_auto     0.9473   0.9386\n",
      "ElasticNetCV           0.5952   0.6099\n",
      "RandomForest_CV        0.9978   0.9386\n"
     ]
    }
   ],
   "source": [
    "## add model score\n",
    "## Score the Model on Training and Testing Set\n",
    "result_scores['RandomForest_CV'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=32, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': (2, 5, 7, 10, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# depth of the tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "## specify grid\n",
    "parameters2 = {'max_depth':(2,5,7,10,20)}\n",
    "## specify model without hyperparameters\n",
    "rf_model = ensemble.RandomForestClassifier(max_features=4,\n",
    "                                           n_estimators=50,\n",
    "                                           random_state=32)\n",
    "## specify search with model\n",
    "clf = GridSearchCV(rf_model,\n",
    "                   parameters2,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## explore best hyperparameters\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n",
      "Logistic_L1_C_auto     0.9516   0.9474\n",
      "Logistic_L2_C_auto     0.9473   0.9386\n",
      "ElasticNetCV           0.5952   0.6099\n",
      "RandomForest_CV        0.9978   0.9386\n",
      "RandomForest_CV2       0.9978   0.9298\n"
     ]
    }
   ],
   "source": [
    "## add model score\n",
    "## Score the Model on Training and Testing Set\n",
    "result_scores['RandomForest_CV2'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that the previous random forest model is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Gradient boost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': (0.1, 0.3, 0.5, 0.7), 'n_estimators': (50, 100, 150, 200)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## specify grid\n",
    "parameters = {'learning_rate':(0.1,0.3,0.5,0.7),\n",
    "              'n_estimators':(50,100,150,200)}\n",
    "## specify model without hyperparameters\n",
    "rf_model = ensemble.GradientBoostingClassifier(random_state=32)\n",
    "## specify search with model\n",
    "clf = GridSearchCV(rf_model,\n",
    "                   parameters,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5, 'n_estimators': 100}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## explore best hyperparameters\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Logistic               0.9077   0.9211\n",
      "Null                   0.6374   0.5877\n",
      "Logistic_L1_C_1        0.9143   0.9211\n",
      "Logistic_L2_C_1        0.9077   0.9211\n",
      "ElasticNet             0.5094   0.5578\n",
      "RandomForest_noCV      1.0      0.9561\n",
      "GradientTree           1.0      0.9474\n",
      "Logistic_L1_C_auto     0.9516   0.9474\n",
      "Logistic_L2_C_auto     0.9473   0.9386\n",
      "ElasticNetCV           0.5952   0.6099\n",
      "RandomForest_CV        0.9978   0.9386\n",
      "RandomForest_CV2       0.9978   0.9298\n",
      "GBC_cv                 1.0      0.9386\n"
     ]
    }
   ],
   "source": [
    "## add model score\n",
    "## Score the Model on Training and Testing Set\n",
    "result_scores['GBC_cv'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,clf.predict(X_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
