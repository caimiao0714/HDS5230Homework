---
title: "Data Table Healthcare Solution"
author: "Evan Carey"
date: "February 7, 2019"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 1 - Gender mortality

> Are men more likely to die than women in this group of patients? Assume people without a date of death in the mortality table are still alive.

We will first need to import the patient data and the mortality data. 

```{r}
library(data.table)
## import needed data
## patient data with gender
patients <- 
  fread('../data/healthcare2/Patient.csv')
## mortality table
mortality <- 
  fread('../data/healthcare2/Mortality.csv')
```

Let's first explore the patient and gender data.

```{r}
library(Hmisc)
describe(patients[,list(PatientID,Gender)])
```

*  It looks like patient ID is distinct which is good. If there were duplicate patient IDs with different genders, we would need to try and sort out which gender is correct. 

*  Gender has some values of 'MISSING', but also has 569 values or actually missing (NA). We should fix this. 

I am going to make a new 'analytic file' with one row for each patient, and their gender. 

```{r}
analytic_patients <-
  patients[,list(PatientID,
                 Gender_clean = factor(Gender,levels=c('male','female')))]
describe(analytic_patients)
```

The next thing we need to do is identify if a patient died. We can use the mortality file to merge in date of deaths for each patient:

```{r}
# Check to make sure the mortality file is unique by patientID (or the merge will have issues)
describe(mortality) ## looks good

## merge Date of death to the analytic file
setkey(analytic_patients, PatientID)
setkey(mortality,PatientID)
analytic_patients[mortality,
                  DateOfDeath := i.DateOfDeath]
## assume missing date of deaths are alive
analytic_patients[is.na(DateOfDeath), Dead := 'No']
analytic_patients[!is.na(DateOfDeath), Dead := 'Yes']
```

Now we can finally answer the question using this file:

```{r}
## overall mortality rate
analytic_patients[,list(mortality_rate= sum(Dead == 'Yes')/.N)]
## rate by gender
analytic_patients[,list(mortality_rate= sum(Dead == 'Yes')/.N),
                  by=Gender_clean]
```

Males appear to have a slightly higher mortality rate in this population then females. However, those missing gender have a slightly lower mortality rate. 

Is this statistically significant? We could use a chi-square test or a logistic regression to check:

```{r}
analytic_patients[,chisq.test(table(Dead,Gender_clean))] # not significant
## using logistic regression
analytic_patients[,summary(glm(Dead=='Yes' ~ Gender_clean, family = binomial))] # not significant

## Include the missing data as a valid level
analytic_patients[is.na(Gender_clean),Gender_clean:='Missing']
## using logistic regression
analytic_patients[,summary(glm(Dead=='Yes' ~ Gender_clean, family = binomial))] # still not significant
```

There is a slight difference in mortality across gender, but it is not statistically significant. 


# 2 - Gender and disease patterns

>> I am interested to know if there are patterns in the disease groups across gender. For every patient with at least one outpatient visit, identify if they have been diagnosed with any of the 22 conditions listed in the diseaseMap table at any time point. You will need to consider all three ICD columns in the outpatientVisit file (not just one). Create a table with the rate of disease for each condition for men, women, and all.



Let's start with identifying the cohort of patients with at least one outpatient visit. 

```{r}
## visits
outpat <- 
  fread('../data/healthcare2/OutpatientVisit.csv')
## check it out
head(outpat)
describe(outpat)
```

Notice there are some missing visitdates...what to do with those?

```{r}
## none?
outpat[is.na(VisitDate)]
## they are blanks
outpat[,head(sort(unique(VisitDate)))]
outpat[,tail(sort(unique(VisitDate)))]
outpat[VisitDate == '']
```

These visits are odd, they don't have a visit date. You could consider removing them from the data, or you could leave them in (since we do have diagnosis codes). Either is reasonable. I will remove them. 

Create a table of patients with at least one outpatient visit:

```{r}
## identify patients at risk
## at least one outpatient visit, remove the missing visit dates
pts_risk <- 
  outpat[VisitDate != '',list(PatientID=unique(PatientID))]
## add their gender
setkey(pts_risk,PatientID)
setkey(analytic_patients,PatientID)
pts_risk[analytic_patients,Gender_clean:=i.Gender_clean]
## summarize the risk set
pts_risk[,.N]
pts_risk[,.N,by=Gender_clean]
```

Ok, now we have identified our population at risk...how can we add in the various diagnoses? We will need the disease maps to map the diagnosis codes to actual diseases.

```{r}
## disease_map
disease_map <- 
  fread('../data/healthcare2/DiseaseMap.csv')
## check the number of conditions
disease_map[,uniqueN(Condition)] 
```

Now let's melt the outpat diagnosis field down to a long form so we ony have to do one merge. Also, lets first subset the outpat diagnoses down to only the patients in our risk set:

```{r}
setkey(outpat,PatientID)
setkey(pts_risk,PatientID)
diag_long <- 
  melt(outpat[pts_risk],
       na.rm = T,
       id.vars = 'PatientID',
       measure.vars = c('ICD10_1', 'ICD10_2', 'ICD10_3'))[value !='',list(PatientID,value)] # remove the blanks after the melt
## check it out
diag_long
## Merge the disease map file
setkey(diag_long,value)
setkey(disease_map,ICD10)
diag_long_patient <- 
  disease_map[diag_long][,.N,by=list(PatientID,Condition)]
diag_long_patient
```

Now we need to combine this data with the patient at risk file. For every patient and condition combination, we want a new row in the dataset, even if the patient does not have that disease! Right now, we only have rows for patient-condition combinations where the patient has the disease. 

I am going to create a 'cartesian product' of the unique conditions and the unique patients. We can then merge this to the diag_long_patient file. 

```{r}
## example cartesian product for clarity
## CJ is the data.table way, returns a data.table
CJ(c(1,2,3),
   c('a','b','c'))
## expand.grid is the base R way, returns a dataframe
expand.grid(c(1,2,3),c('a','b','c'))

## now do this with patients and conditions using CJ
patient_condition <- 
  CJ(PatientID=pts_risk[,unique(PatientID)],
     Condition=disease_map[,unique(Condition)])
## merge in the disease count
setkey(patient_condition,PatientID,Condition)
setkey(diag_long_patient,PatientID,Condition)
patient_condition[diag_long_patient,N:=N]
patient_condition[is.na(N),N:=0]
## merge in gender
setkey(patient_condition,PatientID)
setkey(pts_risk,PatientID)
patient_condition[pts_risk,Gender_clean:=Gender_clean]
## convert N to yes/no (0/1)
patient_condition[,condition_01:=ifelse(N==0,0,1)]
```

Now we have the analytic file to answer the questions that have been asked. 


```{r}
## mean condition for everyone (excluding missing gender - you could also keep them and add another column)
setkey(patient_condition,Gender_clean)
patient_condition[J(c('female','male')),
                  list(Overall = mean(condition_01)),
                  by=Condition]
## save and format
library(scales)
percent(0.34) ## test
condition_all <- 
  patient_condition[J(c('female','male')),
                    list(Overall = percent(mean(condition_01))),
                    by=Condition]
## calculate by gender
condition_gender <- 
  patient_condition[J(c('female','male')),
                    list(Overall = percent(mean(condition_01))),
                    by=list(Condition,Gender_clean)]
## cast to wide
condition_gender_wide <- 
  dcast(condition_gender,Condition ~ Gender_clean)
## Combine with the overall column
setkey(condition_gender_wide,Condition)
setkey(condition_all,Condition)
condition_all[condition_gender_wide]
```

# 3 - Mortality Rate over time

> Calculate the mortality rate for every year between 2005 and 2018. Is it generally increasing, or decreasing? Assume patients are only at risk of death as of their first visit (in the outpatient Visit file). Once they have died, they are no longer at risk in subsequent years

This is not an easy problem (but it is fun.) We need to think about a few things...

1) Who is at risk of death and when? 

2) How do we identify the at risk population every year? 

Let's start with the notion of who is 'at risk' of death. Let's only allow them to be at risk of death as of their first visit. Also, once they are dead, they should no longer be at risk in subsequent years. 

What is our minimum and maximum visit date?

```{r}
## the minimum visit date is blank!
outpat[,list(min(VisitDate),max(VisitDate))]
## let's exclude the blanks
outpat[VisitDate != '',
       list(min(VisitDate),max(VisitDate))]
## 2005 to 2018
```

There are a few ways to do this, and you may have done it differently. I am going to create a cartesian product for the years and patients in the dataset to start. Then I will work on identifying for each year and patient, is the patient at risk? I will only allow patients with at least one outpatient visit without a missing date in the risk set. 

```{r}
## identify unique patients / years combination
patient_years <- 
  CJ(PatientID=outpat[VisitDate!='',unique(PatientID)],
     Years=2005:2018)
## identify first outpat date
pat_min_vis <- 
  outpat[VisitDate!='',list(min_vis = min(VisitDate)),by=PatientID]
## add to file
setkey(patient_years,PatientID)
setkey(pat_min_vis,PatientID)
patient_years[pat_min_vis,
              min_vis:=as.numeric(substr(min_vis,start = 1,stop = 4))]
```

Now we should look into the mortality data. For each year and for each patient, were they dead? 

```{r}
## add mortality
setkey(mortality,PatientID)
patient_years[mortality,
              death_yr:=as.numeric(substr(DateOfDeath,start = 1,stop = 4))]
## compare years to see if patient died in a given year
patient_years[Years >= death_yr, dead := 1]
patient_years[is.na(dead), dead :=0]
## spot check the data
patient_years[PatientID == 1]
patient_years[PatientID == 2]
## looks good
```

Now let's calculate the at risk variable. For every patient-year combination, was the patient at risk of death?

```{r}
## implement logic for at-risk
patient_years[Years < min_vis,
              at_risk := 'no']
patient_years[Years >= min_vis,
              at_risk := 'yes']
patient_years[Years > death_yr,
              at_risk := 'no']
## spot check again
patient_years[PatientID == 1]
patient_years[PatientID == 2]
## looks good!
```

Now we can limit the analytic risk set to patients at risk, then calculate the mortality rate by year!

```{r}
## calculate mortality by year
patient_years[at_risk == 'yes',
              list(n_unique_patients = uniqueN(PatientID),
                   n_at_risk = .N,
                   n_dead = sum(dead),
                   mortality_rate=mean(dead)),
              keyby=Years]  ## keyby sorts it by years
```

It is comforting to see that the number of patients at risk is equal to the number of unique patients every year, otherwise we would be double counting someone!

It looks like the mortality rate may be slightly decling over time. Why is the mortality rate in 2018 so small? Because the max date was 2018-06-01...we only had 5 months of follow-up to catch deaths in 2018. In the other years, we had a full year.